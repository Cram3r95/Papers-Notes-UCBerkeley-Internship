# Papers-Notes:

This repository contains my tasks summary at the end of each day, paper (Pa) and posts (Po) reading notes on deep learning and machine learning, as well as tutorials covered, mainly focused on my thesis "Deep Learning based Multi-Object Tracking and Motion Prediction for Intelligent Vehicles applications" during my internship at UCBerkeley (April - July 2022).

# Courses:

(NYU) Deep Learning Course: https://atcold.github.io/pytorch-Deep-Learning/ \
(UPenn) Graph Neural Networks Course: https://gnn.seas.upenn.edu/

# Notes: 

### April 
1st: 
<ul>
<li><p> First contact with the MSC lab. 
<li><p> Interview with the advisor (Wei Zhan) and PostDoc student (Chen Tang) to define my tasks. 
<li><p> Start to sort my UCBerkeley documents.
</ul>
4th: 
<ul>
<li><p> Finish to sort my UCBerkeley documents.  
<li><p> Start to study the NYU Deep Learning course -> Week 1 (50:33 YT video).
<li><p> Start to study the UPenn GNNs course (Introduction covered)   
<li><p> Join to MSC_Auto Slack and get papers to read about the new project: Explainable AI to study behavior prediction models 
</ul>
5th: 
<ul>
<li><p> Almost all paperwork is done.
<li><p> Read Project "Explainable AI for behaviour-prediction models".
<li><p> Finish to watch the first lecture (NYU-DL): "History, motivation, and evolution of Deep Learning". What's left: Highlight the theory of 1.1. and 1.2.
<li><p> See Lecture 1.1. "Graph Neural Networks" (UPenn-GNNs).
<li><p> Install LaneGCN and start reading its paper.
</ul>
6th: 
<ul>
<li><p> See Practicum 1 (NYU-DL). What's left: Highlighy Lecture 1 and Practicum 1 theory, and run practicum 1 code.
<li><p> See Lecture 1.2. "Machine Learning on Graphs: The Why" (UPenn-GNNs).
<li><p> See Video 1 (Essence of Linear Algebra) and SVD (Singular Value Decomposition).
<li><p> Start reading "You Mostly Walk Alone. Analizing Feature Attribution in Trajectory Prediction" paper (arXiv preprint).
</ul>
7th: 
<ul>
<li><p> Finish reading "You Mostly Walk Alone. Analizing Feature Attribution in Trajectory Prediction" paper (arXiv preprint).
</ul>
8th: 
<ul>
<li><p> Read post "Kullback-Leibler Divergence for Machine Learning".
<li><p> Read post "A Quick Intro to Leave-One-Out Cross-Validation (LOOCV)".
<li><p> Read post "Review. Multimodal Trajectory Predictions for Autonomous Driving Using Deep Convolutional Networks".
<li><p> Almost finished with "Exploring Social Posterior Collapse in Variational Autoencoder for Interaction Modeling" paper.
<li><p> Start reading "Interventional Behavior Prediction Avoiding Overly Confident Anticipation in Interactive Prediction" paper.
<li><p> Start to second lecture (NYU-DL): "Stochastic gradient descent and backpropagation" (6:53 YT video)
</ul>
13th: 
<ul>
<li><p> Finish reading "Exploring Social Posterior Collapse in Variational Autoencoder for Interaction Modeling" paper (NeurIPS 2021)
<li><p> Request Cal 1 Card
<li><p> Finish reading "Interventional Behavior Prediction: Avoiding Overly Confident Anticipation in Interactive Prediction" (in submission, IROS 2022)
<li><p> Start reading about Shapley values https://christophm.github.io/interpretable-ml-book/shapley.html
</ul>
18th: 
<ul>
<li><p> Read post "How to Manage and Restore Tmux Sessions in Linux".
<li><p> Start reading "Learning Lane Graph Representations for Motion Forecasting" paper (ECCV 2020).
<li><p> Enhanced README of "Exploring Attention GAN for Vehicle Motion Prediction" paper (in submission, ITSC 2022).
<li><p> Finish 00-logic_neuron_programming.ipynb assignment (DL course).
<li><p> Continue reading Shapley values.
<li><p> Continue studying GNNs Lecture 1.
</ul>
19th: 
<ul>
<li><p> Finish reading "Learning Lane Graph Representations for Motion Forecasting" paper (ECCV 2020).
<li><p> Start reading "VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation"
<li><p> Finish 01-tensor_tutorial.ipynb assignment (DL course).
<li><p> Finish reading Shapley values.
</ul>
20th: 
<ul>
<li><p> Organize Workshop: "Accelerating_CUDA_C++_Applications_with_Multiple_GPUs" (NVIDIA DLI).
<li><p> Read Part 1 Workshop: "Building Transformer-Based Natural Language Processing Applications".
<li><p> Finish Part 1 Workshop: "Building Transformer-Based Natural Language Processing Applications".  
  
<li><p> Start reading "VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation"
<li><p> Finish 01-tensor_tutorial.ipynb assignment (DL course).
<li><p> Finish reading Shapley values.
</ul>

  
Total papers: 4 \
Total posts: 4 \

### May 
Total papers: \
Total posts: \

### June 
Total papers: \
Total posts: \

### July 
Total papers: \
Total posts: \
